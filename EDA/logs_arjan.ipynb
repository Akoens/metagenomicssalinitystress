{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logbook Metagenomics Project Salinity Stress\n",
    "## abstract\n",
    "## Introduction\n",
    "## Workflow / Pipeline\n",
    "\n",
    "\n",
    "## Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date: 5-03-2024**  \n",
    "\n",
    "**Goals**  \n",
    "- Seek tools needed for processing and analysing our data\n",
    "\n",
    "**Results**  \n",
    "\n",
    "\n",
    "\n",
    "I was able to find a wikipedia page giving a nive overview of all the steps involved in a metagenomics analysis. [metagenomics](https://en.wikipedia.org/wiki/Metagenomics). For us the main interest is in the non-assembled analysis. Because unreliable reads should not be assambled and we don't want homunculi genomes that we then try to find the organisms for. We want to use every read as a reference to find our potential organisms. This is called classification for which i have found atleast \n",
    "\n",
    "This was a good reference project [here](https://pmc.ncbi.nlm.nih.gov/articles/PMC8086013/)\n",
    "I also found nanoclass2 which can taxonomic classify using a bunch of tools, though it seems this is tool does everything for you, which might not be something for us [here](https://ndombrowski.github.io/NanoClass2/source/run_nanoclass.html)\n",
    "\n",
    "Kraken2, Kaiju, MegaBLAST, RDP,   ??> IDTAXA, [SPINGO](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0747-1)\n",
    "\n",
    "https://github.com/lsbnb/MetaSquare\n",
    "\n",
    "\n",
    "A big question is which classifiers should we use to guarentee that the classified organisms are accurate. Because we don't know what organisms to expect and want to do a broad as possible search, a combination of these tools would be good choice.\n",
    "\n",
    "Porechop for trimming adapters \n",
    "Filtlong or nanofilt for filtering reads based on quality.\n",
    "Centrifuge, Kraken2, RDP and MegaBLAST for Taxonimy classification.\n",
    "\n",
    "\n",
    "**Refelction**  \n",
    "There is a large variety of tools and directions a metagenommics project can go. I am having a hard time creating something concreate, Ronald is hinting, sortof, but i am only more confused on what would be the best direction for our project. I know for sure classifing will get us a good way. another potential direction might be comparitive metagenomics.\n",
    "\n",
    "**Next Steps**  \n",
    "- Testing Trimming tools  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date: 11-03-2025**  \n",
    "\n",
    "**Goals**  \n",
    "- Setting up Kaiju in environment\n",
    "\n",
    "**Results**  \n",
    "After having a chat with Martijn, we have come to learn that our data has already been preprocessed. This means that trimming and removing adapters/barcodes is not nessisary anymore, for Martijn has already done this. Some waisted time here looking into preprocessing of data.  \n",
    "The next step to processing our data will be to classify them and see what organisms exists in our samples. I already collected a few tools that could do this, but Martijn noted that Kraken2 and Kaiju are our best choices. Centrifuge was the predicessor of Kraken2, and after looking a bit better RDP and SPINGO are outdated begin between 5-10 years old and not being activaly maintained.\n",
    "\n",
    "We also have the option to do functional annotation analaysis to see what proteins/pathways are pressent and analyse what their influence might be, but this is not relevent for awnsering our research objective. So we will omit this branch of metagenomics for future research and focus on making a good pipeline and interpreting our results. In note for future, if we can't identify a significant number of organisms, we could assemble genomes, but again this should not be nessisary.\n",
    "\n",
    "\n",
    "\n",
    "Kaiju can easilly be installed via conda, after installing an index needs to be build or en pre-build index needs to be downloaded. The best course of action is to use the pre-build indexes, we don't have access to any specific databases/sets so a generic one is fine. The nr database containing a subset of the NCBI BLAST-rn database is a good coverage for Archaa, bacteria and viruses. Additionally for us fungi are interessting because of known interactions between plants and fungi supporting plant growth. So the fungi database or maybe better the nr_euk database which is like nr, but also includes fungi and microbial eukaryotes.\n",
    "\n",
    "For now i will try and download the nr_euk and the fungi database index, but martijn said he will make them availible on the network aswell.\n",
    "\n",
    "\n",
    "**Reflection**  \n",
    "After thinking of our steps to be taken, run them by our teachers for some validation, this can save us some effort.\n",
    "\n",
    "**Next steps**  \n",
    "- Running Kaiju on data\n",
    "- Setting up Snakemake script\n",
    "- Adding Kaiju command to Snakemake\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date: 12-03-2025**  \n",
    "\n",
    "**Goals**  \n",
    "- Running Kaiju on test data\n",
    "- Starting basic snakemake pipline with config\n",
    "\n",
    "**Results**  \n",
    "Kaiju takes 3 atleast parameters, the .fmi which is the index file, a nodes.dmp file (also from the index) and the fastq file (which can be paired end aswell). Besides that a -z can be added for multithreading, kaiju-mulit can be used to supply a list of fastq files, which is what i want to use.\n",
    "\n",
    "I added the basis for snakemake and a snakemake config. I also discovered that kaiju-multi is not part of the conda packages. So unless i want to install i seperatly i need to make do with just normal kaiju. Snakemake should be able to handel some of the parallel processing that kaiju would have otherwise done so it should be fine. \n",
    "\n",
    "```bash\n",
    "kaiju -t /students/2024-2025/Thema07/metagenomics/zoutstress/kaiju_index/kaiju_db_fungi/nodes.dmp -f /students/2024-2025/Thema07/metagenomics/zoutstress/kaiju_index/kaiju_db_fungi/kaiju_db_fungi.fmi -i /commons/Themas/Thema07/metagenomics/zoutstress/16S/zout_20_30cm_rep2/FAY08769_pass_barcode10_85e26567_1cef8301_3.fastq.gz -o /students/2024-2025/Thema07/metagenomics/zoutstress/outputs/kaiju/FAY08769_pass_barcode10_85e26567_1cef8301_3.out\n",
    "```\n",
    "\n",
    "I Tried running a single instance of kaiju via the cli, but i would seem kaiju is having trouble recognising the file type. I tries two different fastq files to see if i might have been a problem with just the one file, but it appears to presist. Not really sure how to fix this, ill have to ask some advice.\n",
    "\n",
    "```bash\n",
    "kaiju -t /students/2024-2025/Thema07/metagenomics/zoutstress/kaiju_index/kaiju_db_fungi/nodes.dmp -f /students/2024-2025/Thema07/metagenomics/zoutstress/kaiju_index/kaiju_db_fungi/kaiju_db_fungi.fmi -i /students/2024-2025/Thema07/metagenomics/zoutstress/testing_data/16s/zout_20_30cm_rep2/FAY08769_pass_barcode10_85e26567_1cef8301_3.fastq -o /students/2024-2025/Thema07/metagenomics/zoutstress/outputs/kaiju/FAY08769_pass_barcode10_85e26567_1cef8301_3.out\n",
    "```\n",
    "running it on the test data seems to work. These files have been decompressed.\n",
    "\n",
    "```bash\n",
    "kaiju -t /students/2024-2025/Thema07/metagenomics/zoutstress/kaiju_index/kaiju_db_fungi/nodes.dmp -f /students/2024-2025/Thema07/metagenomics/zoutstress/kaiju_index/kaiju_db_fungi/kaiju_db_fungi.fmi -i /students/2024-2025/Thema07/metagenomics/zoutstress/outputs/FAY08769_pass_barcode10_85e26567_1cef8301_3.fastq.gz -o /students/2024-2025/Thema07/metagenomics/zoutstress/outputs/kaiju/FAY08769_pass_barcode10_85e26567_1cef8301_3.out\n",
    "```\n",
    "\n",
    "After trying the same command on a recompressed testdata file the same error occures.\"Auto-detection of file type for file /students/2024-2025/Thema07/metagenomics/zoutstress/outputs/FAY08769_pass_barcode10_85e26567_1cef8301_3.fastq.gz failed.\"\n",
    "\n",
    "So even though in the examples of kaiju compressed fastq files are used. I seem to not be able to use them.\n",
    "\n",
    "\n",
    "\n",
    "**Reflection**  \n",
    "I definitly need to exercise more with snakemake i am having trouble writing the nessisary rules for running kaiju.\n",
    "\n",
    "**Next steps**  \n",
    "- Continue developing snakemake rules\n",
    "- Run multi instance Kaiju\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date: 14-03-2024**  \n",
    "\n",
    "**Goals**\n",
    "- Concatting data\n",
    "- Running Kaiju on data\n",
    "- Converting to Krona\n",
    "\n",
    "**Results**  \n",
    "I gained some more insights on our data from ronald. The minIOn creates a whole bunch of fastq files, but they all belong to the same sample. Meaning that all the fastq files can be concatted instead of being treated seperatly. I wrote a small bash command to handle the concatination of all the  fastq files. This will have to be incorperated into snakemake later. For now we have 8 fastq files that makes running kaiju a lot simpler.\n",
    "\n",
    "```bash\n",
    "cd /commons/Themas/Thema07/metagenomics/zoutstress/\n",
    "data_dir=\"/students/2024-2025/Thema07/metagenomics/zoutstress/data/\"\n",
    "find . -maxdepth 2 -mindepth 2 -type d | parallel \"mkdir -vpm 770 ${data_dir}{//}; cat {}/* > ${data_dir}{}.fastq.gz\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Reflection**  \n",
    "\n",
    "**Next Steps**  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date: xx-xx-xxxx**  \n",
    "**Goals:**  \n",
    "**Results**  \n",
    "- What\n",
    "- Why\n",
    "- How\n",
    "**Reflection**  \n",
    "**Next Steps**  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
